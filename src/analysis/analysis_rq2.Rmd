---
title: "analysis_rq2"
author: "√Ålvaro Domingo"
date: "2023-07-14"
output: pdf_document
---

```{r}
library(VGAM)
library(ggplot2)
library(dplyr)
library(tidyr)
library(lmtest)
library(stringr)
library(emmeans)
library(aod)
library(plm)
library(reshape2)
```
## Load data

```{r}
all_data = subset(read.csv("../../data/processed/all_data.csv"), select=-X)
datasets = read.csv("../../data/raw/datasets.csv")
datasets$dataset[datasets$dataset=="visual_domain_decathlon/aircraft"] = "aircraft"
all_data = left_join(all_data, datasets, by="dataset")
high_energy = c("birdsnap", "cifar10", "cifar100", "food101", "sun397")
N = 50
s = 10

center = function(df, attribute) {
  return (ave(as.vector(df[,attribute]), df$dataset, FUN = function(x) x - mean(x)) + mean(df[,attribute]))
}
```

### Visualization

```{r}
var.plot = "accuracy"

par(mfrow=c(3,4), mar=c(2.3,2.3,1,0), oma=c(0,0,0,0), mgp=c(1.3,0.5,0))
# Loop over datasets
for (d in datasets$dataset) {
  history_part <- all_data[all_data$dataset == d, ]
  
  # Plot each subplot
  plot(NULL, xlim=c(0,N), ylim=range(history_part[,var.plot]), xlab="Epoch", ylab="Validation F-score", main=d)
  for (i in seq(0, N, by=s)) {
    branch <- history_part[history_part$intervention == i & history_part$mode == "freeze", ]
    lines(branch$epoch, branch[,var.plot], col="green", type='l')
    branch <- history_part[history_part$intervention == i & history_part$mode == "quant", ]
    lines(branch$epoch, branch[,var.plot], col="red", type='l')
  }
  branch <- history_part[history_part$mode == "base", ]
  lines(branch$epoch, branch[,var.plot], col="blue", type='l')
  
  rational = function(x, c, b) {c / (x + b)}
  y = history_part$score[1:50]
  fit = nls(y ~ rational(seq(1,50), c, b), start = list(c = 100, b = 10))
  lines(predict(fit, seq(1,50)), col="black")
  abline(v = -coef(fit)[["b"]] + sqrt(coef(fit)[["c"]]))
  print(d)
  print(-coef(fit)[["b"]] + sqrt(coef(fit)[["c"]]))
}
```

##Data prep 

```{r}
panel.base = all_data %>%
  subset(mode=="base", select=c(dataset, epoch, accuracy, val_accuracy)) %>%
  group_by(dataset) %>%
  mutate(val_lag1 = dplyr::lag(val_accuracy, 1),
         val_lag2 = dplyr::lag(val_accuracy, 2),
         val_lag3 = dplyr::lag(val_accuracy, 3),
         trn_lag1 = dplyr::lag(accuracy, 1),
         trn_lag2 = dplyr::lag(accuracy, 2),
         trn_lag3 = dplyr::lag(accuracy, 3)
         ) %>%
  ungroup() %>%
  as.data.frame() %>%
  drop_na()

get_prev <- function(row, df, attribute, n) {
  dataset <- row["dataset"]
  mode <- row["mode"]
  intervention <- as.numeric(row["intervention"])
  epoch <- as.numeric(row["epoch"])
  if (epoch <= n) {return (NA)}
  if (epoch - n <= intervention) {
    return (df[df$dataset == dataset & 
                 df$mode == "base" &
                 df$epoch == epoch - n,
               attribute])
  }
  if (epoch - n > intervention) {
    return (df[df$dataset == dataset & 
                 df$mode == mode &
                 df$intervention == intervention &
                 df$epoch == epoch - n,
               attribute])}
}

get_all_previous = function(i, df) {
  if (df[i,"intervention"] == 0) {
    return (df[df$intervention == 0 & df$mode == df[i,"mode"] & df$epoch < df[i,"epoch"],])
  }
  return(rbind(
    df[df$intervention == 0 & df$epoch < df[i,"intervention"],],
    df[df$intervention == df[i,"intervention"] & df$mode == df[i,"mode"] & df$epoch < df[i,"epoch"],]
  ))
}

panel.data = all_data[str_split("dataset,epoch,intervention,mode,val_accuracy,accuracy", ",")[[1]]]
for (attr in c("val_accuracy", "accuracy", "mode")) {
  for (n in 1:10) {
    panel.data[[paste0(attr, "_lag", n)]] <- apply(panel.data, 1, get_prev, df=panel.data, attribute=attr, n=n)
  }
}
```

## Accuracy prediction

### Fit panel data (only base mode)

```{r}
ppanel.base = pdata.frame(panel.base, index=c("dataset", "epoch"))


res.ols = lm(val_accuracy ~ val_lag1 + val_lag2 + val_lag3, data=panel.base)
res.fe = lm(val_accuracy ~ val_lag1 + val_lag2 + val_lag3 + dataset, data=panel.base)
res.ols2 = plm(val_accuracy ~ val_lag1 + val_lag2 + val_lag3, data = ppanel.base, model = "pooling")
res.fe2 = plm(val_accuracy ~ val_lag1 + val_lag2 + val_lag3, data = ppanel.base, model = "within")
res.re2 = plm(val_accuracy ~ val_lag1 + val_lag2 + val_lag3, data = ppanel.base, model = "random")

print("------- SUMMARIES ---------")
print(summary(res.ols))
print(summary(res.ols2)$fstatistic$p.value)
print(summary(res.fe))
print(summary(res.fe2)$fstatistic$p.value)
print(summary(res.re2))
print(summary(res.re2)$fstatistic$p.value)
print("------- OLS VS FE ---------")
print(anova(res.ols, res.fe))
print(anova(res.ols, res.fe)$"Pr(>F)")
print(wald.test(vcov(res.fe), coef(res.fe), Terms=5:15))
print(wald.test(vcov(res.fe), coef(res.fe), Terms=5:15)$result$chi2["P"])
print("------- FE VS RE --------- ")
print(phtest(res.fe2, res.re2))
print(phtest(res.fe2, res.re2)$p.value)
```


### Check number of lagged values
```{r}
for (i in 1:10) {
  part_data = panel.data[,c(1:6, 7:(6+i), 17:(16+i), 27:(26+i))] %>% drop_na()
  form = formula(paste("val_accuracy ~ dataset +", 
                       paste(paste0("val_accuracy_lag", 1:i), collapse="+"), "+",
                       paste(paste0("mode_lag", 1:i), collapse="+"), "+", "mode"))
  res.fe = lm(form, data=part_data)
  #coefs = summary(res.fe)$coefficients[13:(i+12),]
  coefs = summary(res.fe)$coefficients[(13+i):(3*i+14),]
  coefs[,4] = i * coefs[,4]  # Compensate (Bonferroni?)
  print(coefs)
}
```


```{r}
for (i in 2:10) {
  part_data = panel.data[,c(1:6, 7:(6+i), 17:(16+i), 27:(26+i))] %>% drop_na()
  form1 = formula(paste("val_accuracy ~ dataset +", 
                       paste(paste0("val_accuracy_lag", 1:(i-1)), collapse="+"), "+",
                       paste(paste0("mode_lag", 1:(i-1)), collapse="+"), "+", "mode"))
  form2 = formula(paste("val_accuracy ~ dataset +", 
                       paste(paste0("val_accuracy_lag", 1:i), collapse="+"), "+",
                       paste(paste0("mode_lag", 1:i), collapse="+"), "+", "mode"))
  res.fe1 = lm(form1, data=part_data)
  res.fe2 = lm(form2, data=part_data)
  print(anova(res.fe1, res.fe2))
}
```

```{r}
for (i in 1:4) {
  part_data = panel.data[,c(1:6, 7:10, 17:20, 27:30)] %>% drop_na()
  part_data[part_data == "quant"] = "base"
  form = formula(paste("val_accuracy ~ dataset +", 
                       paste(paste0("val_accuracy_lag", 1:4), collapse="+"), "+",
                       paste(paste0("mode_lag", 1:i), collapse="+"), "+", "mode"))
  res.fe = lm(form, data=part_data)
  coefs = summary(res.fe)$coefficients[17:(i+17),]
  #coefs = summary(res.fe)$coefficients[(13+i):(3*i+14),]
  coefs[,4] = i*coefs[,4]
  print(coefs)
}

for (i in 1:4) {
  part_data = panel.data[,c(1:6, 7:10, 17:20, 27:30)] %>% drop_na()
  part_data[part_data == "quant"] = "base"
  form = formula(paste("val_accuracy ~ dataset +", 
                       paste(paste0("val_accuracy_lag", 1:4), collapse="+"), "+",
                       paste0("mode_lag", i), "+", "mode"))
  res.fe = lm(form, data=part_data)
  print(summary(res.fe))
}
```

### Estimate dataset parameter
```{r}
n.rep = 1
time.measure = system.time({
  for (rep in 1:n.rep) {
    errors.1 = c()
    gt = c()
    for (dataset in datasets$dataset) {
      part_data = panel.data[panel.data$dataset != dataset, c(1:6, 7:10, 17:20, 27)] %>% drop_na()
      part_data[part_data == "quant"] = "base"
      extra_data = panel.data[panel.data$dataset == dataset, c(1:6, 7:10, 17:20, 27)] %>% drop_na()
      extra_data[extra_data == "quant"] = "base"
      for (i in 1:nrow(extra_data)) {
        if (extra_data[i,"epoch"] <= 6) {next}
        complete_data = rbind(part_data, get_all_previous(i, extra_data))
        res.fe = lm(val_accuracy ~ dataset + val_accuracy_lag1 + val_accuracy_lag2 + 
                      val_accuracy_lag3 + val_accuracy_lag4 + mode_lag1 + mode, data=complete_data)
        pred = predict(res.fe, newdata=extra_data[i,c(1,7:10,15,4)])
        errors.1 = c(errors.1, pred - extra_data[i,"val_accuracy"])
        gt = c(gt, extra_data[i,"val_accuracy"])
      }
    }
  }
})
print(time.measure[3]/n.rep)
print(sum(errors.1**2))
print(mean(errors.1**2))
print(mean(abs(errors.1)))
print(mean(abs(errors.1)/gt))
```


```{r}
n.rep = 1
time.measure = system.time({
  for (rep in 1:n.rep) {
    errors.2 = c()
    gt = c()
    for (dataset in datasets$dataset) {
      part_data = panel.data[panel.data$dataset != dataset, c(1:6, 7:10, 17:20, 27)] %>% drop_na()
      part_data[part_data == "quant"] = "base"
      extra_data = panel.data[panel.data$dataset == dataset & 
       ((all_data$intervention == 30 & all_data$mode == "quant") |
        (all_data$epoch < 30 & all_data$mode == "base")), c(1:6, 7:10, 17:20, 27)] %>% drop_na()
      res.fe = lm(val_accuracy ~ dataset + val_accuracy_lag1 + val_accuracy_lag2 + 
                      val_accuracy_lag3 + val_accuracy_lag4 + mode_lag1 + mode, data=part_data)
      coefs = res.fe$coefficients[12:17]
      n.count = 0
      for (i in 1:nrow(extra_data)) {
        if (extra_data[i,"epoch"] <= 6) {next}
        n.count = n.count + 1
        previous_data = get_all_previous(i, extra_data)[c(7:10,15,4,5)]
        previous_data[5:6] = (previous_data[5:6] == "freeze")
        previous_preds = colSums(t(previous_data[1:6]) * coefs)
        offset = mean(previous_data$val_accuracy) - mean(previous_preds)
        
        pred = c(as.numeric(extra_data[i,7:10]), extra_data[i,15]=="freeze", extra_data[i,4]=="freeze")
        pred = sum(pred * coefs) + offset
        errors.2 = c(errors.2, pred - extra_data[i,"val_accuracy"])
        gt = c(gt, extra_data[i,"val_accuracy"])
        
      }
    }
  }
})

print(time.measure[3]/n.rep)
print(sum(errors.2**2))
print(mean(errors.2**2))
print(mean(abs(errors.2)))
print(mean(abs(errors.2)/gt))
```


```{r}
n.rep = 1
time.measure = system.time({
  for (rep in 1:n.rep) {
    errors.3 = c()
    gt = c()
    epochs.count = c()
    for (dataset in datasets$dataset) {
      part_data = panel.data[panel.data$dataset != dataset, c(1:6, 7:10, 17:20, 27)] %>% drop_na()
      part_data[part_data == "quant"] = "base"
      extra_data = panel.data[panel.data$dataset == dataset, c(1:6, 7:10, 17:20, 27)] %>% drop_na()
      res.fe = lm(val_accuracy ~ dataset + val_accuracy_lag1 + val_accuracy_lag2 + 
                      val_accuracy_lag3 + val_accuracy_lag4 + mode_lag1 + mode, data=part_data)
      coefs = res.fe$coefficients[12:17]
      n.count = 0
      for (i in 1:nrow(extra_data)) {
        if (extra_data[i,"epoch"] <= 6) {znext}
        n.count = n.count + 1
        previous_data = get_all_previous(i, extra_data)[c(7:10,15,4,5)]
        previous_data[5:6] = (previous_data[5:6] == "freeze")
        previous_preds = colSums(t(previous_data[1:6]) * coefs)
        new_fit = lm(previous_data$val_accuracy ~ previous_preds)
        
        pred = c(as.numeric(extra_data[i,7:10]), extra_data[i,15]=="freeze", extra_data[i,4]=="freeze")
        pred = sum(pred * coefs) * new_fit$coefficients[2] + new_fit$coefficients[1]
        errors.3 = c(errors.3, pred - extra_data[i,"val_accuracy"])
        epochs.count = c(epochs.count, extra_data[i,"epoch"])
        gt = c(gt, extra_data[i,"val_accuracy"])
      }
    }
  }
})

print(time.measure[3]/n.rep)
print(sum(errors.3**2))
print(mean(errors.3**2))
print(mean(abs(errors.3)))
print(mean(abs(errors.3)/gt))
```

```{r}
plot(unique(epochs.count), tapply(errors.1, epochs.count, mean), type='l', col="blue")
lines(unique(epochs.count), tapply(errors.2, epochs.count, mean), col="green")
lines(unique(epochs.count), tapply(errors.3, epochs.count, mean), col="red")
legend("topright", legend = c("Model refitting", "Additive parameter estimation", "Regressive parameter estimation"), col = c("blue", "green", "red"), lty = 1)
```

### Estimation of coefficients for reference

```{r}
part_data = panel.data[c(1:6, 7:10, 17:20, 27)] %>% drop_na()
res.fe = lm(val_accuracy ~ dataset + val_accuracy_lag1 + val_accuracy_lag2 + 
                val_accuracy_lag3 + val_accuracy_lag4 + mode_lag1 + mode, data=part_data)
print(summary(res.fe))
print(names(res.fe$coefficients[13:length(res.fe$coefficients)]))
print(unname(res.fe$coefficients[13:length(res.fe$coefficients)]))
```

```{r}
part_data = panel.data[c(1:6, 7:10, 17:20, 27)] %>% drop_na()
res.fe = lm(accuracy ~ dataset + accuracy_lag1 + accuracy_lag2 + 
                accuracy_lag3 + accuracy_lag4 + mode_lag1 + mode, data=part_data)
print(summary(res.fe))
print(names(res.fe$coefficients[13:length(res.fe$coefficients)]))
print(unname(res.fe$coefficients[13:length(res.fe$coefficients)]))
```

## Energy prediction

### Test for autocorrelation (temporal independence)

```{r}
var.plot = "energy_nvidia"

par(mfrow=c(3,4), mar=c(2.3,2.3,1,0), oma=c(0,0,0,0), mgp=c(1.3,0.5,0))
# Loop over datasets
for (d in datasets$dataset) {
  history_part <- all_data[all_data$dataset == d, ]
  
  # Plot each subplot
  plot(NULL, xlim=c(0,N), ylim=range(history_part[,var.plot]), xlab="Epoch", ylab="Validation F-score", main=d)
  for (i in seq(0, N, by=s)) {
    branch <- history_part[history_part$intervention == i & history_part$mode == "freeze", ]
    lines(branch$epoch, branch[,var.plot], col="green", type='l')
    branch <- history_part[history_part$intervention == i & history_part$mode == "quant", ]
    lines(branch$epoch, branch[,var.plot], col="red", type='l')
  }
  branch <- history_part[history_part$mode == "base", ]
  lines(branch$epoch, branch[,var.plot], col="blue", type='l')
}

par(mfrow=c(2,1), mar=c(3,3,1.4,0), mgp=c(1.7,0.5,0), cex.axis=1.2, cex.lab=1.5, cex.main=1.5)
setups = list("base"=c(0,"blue"), "freeze"=c(-0.1,"green"), "quant"=c(0.1,"red"))
# Loop over datasets
for (i in 1:2) {
  d = datasets$dataset[i]
  # Plot each subplot
  plot(NULL, xlim=c(0,10), ylim=c(-0.3,1), xlab="Lag", ylab="Autocorrelation", main=d)
  for (m in names(setups)) {
    history_part <- all_data[all_data$dataset == d & all_data$mode == m & all_data$intervention == 0, var.plot]
    autocorr = acf(history_part, lag.max=10, plot=FALSE)$acf
    lines(seq(0,10) + as.numeric(setups[[m]][1]), autocorr, col=setups[[m]][2], type="h")
  }
  abline(h=c(0, 1.96/sqrt(50), -1.96/sqrt(50)), col=c("black", "red", "red"))
}


lb_df = all_data[all_data$intervention == 0,] %>%
  group_by(dataset, mode) %>%
  summarise(p_value = Box.test(energy_nvidia, lag=10, type = "Ljung-Box")$p.value)

# Create bar plot of p-values
ggplot(lb_df, aes(x = dataset, y = p_value, color = mode)) +
  geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
  scale_color_manual(values = c("blue", "green", "red"), name = "Training mode",
                     labels = c("Base training", "Layer freezing", "Model quantization")) +
  labs(x = "Dataset", y = "Ljung-Box p-value") +
  theme(axis.text.x = element_text(angle = 20, vjust = 1, hjust = 1)) +
  geom_hline(yintercept = 0.05, color="red") +
  theme_minimal() +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 20, hjust = 1),
    axis.ticks.x = element_line(color = "black", size = 0.5),
    axis.text = element_text(size = 14), axis.title = element_text(size = 16),
    legend.text = element_text(size = 12), legend.title = element_text(size = 14)
  )
```

### Test for normality

```{r}
all_data2 <- all_data %>%
  group_by(dataset, mode) %>%
  mutate(mad = median(abs(energy_nvidia - median(energy_nvidia)))) %>%
  filter(abs(energy_nvidia - median(energy_nvidia)) < 10 * mad) %>%
  select(-mad)
all_data2 <- all_data2 %>%
  group_by(dataset) %>%
  mutate(energy_nvidia_scaled = as.numeric(scale(energy_nvidia, center = min(energy_nvidia), scale = max(energy_nvidia) - min(energy_nvidia))))
all_data2$mode <- as.factor(all_data2$mode)

diffs = 
  merge(count(all_data, dataset, mode), count(all_data2, dataset, mode), by = c("dataset", "mode"), all = TRUE) %>%
    mutate(diff = n.x - n.y, percent = (n.x - n.y) / n.x * 100) %>%
    select(dataset, mode, diff, percent)
print(xtabs(cbind(diff, percent) ~ dataset + mode, data=diffs))

ggplot(all_data2, aes(x=epoch, y=energy_nvidia_scaled, color=mode)) +
  geom_point(alpha=0.5, size=1) +
  scale_color_manual(values = c("blue", "green", "red"), name = "Training mode",
                     labels = c("Base training", "Layer freezing", "Model quantization")) +
  labs(x = "Epoch", y = "Scaled energy") +
  facet_wrap(~dataset, nrow = 3, ncol = 4) +
  theme_minimal() +
  theme(legend.position = "top", 
        axis.text = element_text(size = 14), axis.title = element_text(size = 16),
        legend.text = element_text(size = 12), legend.title = element_text(size = 14),
        strip.text = element_text(size = 13))

ggplot(all_data2, aes(x = energy_nvidia_scaled, fill = mode)) +
  geom_histogram(position = "identity", alpha = 0.5, bins = 30) +
  scale_fill_manual(values = c("blue", "green", "red"), name = "Training mode",
                     labels = c("Base training", "Layer freezing", "Model quantization")) +
  labs(x = "Scaled energy", y = "Count") +
  facet_wrap(~dataset, nrow = 3, ncol = 4) +
  theme_minimal() +
  theme(legend.position = "top", 
        axis.text = element_text(size = 14), axis.title = element_text(size = 16),
        legend.text = element_text(size = 12), legend.title = element_text(size = 14),
        strip.text = element_text(size = 13))

ggplot(all_data2, aes(sample=energy_nvidia_scaled, color=mode)) +
  geom_qq(alpha=0.3) +
  scale_color_manual(values = c("blue", "green", "red"), name = "Training mode",
                     labels = c("Base training", "Layer freezing", "Model quantization")) +
  facet_wrap(~dataset, nrow = 3, ncol = 4) +
  labs(x = "Theoretical Quantiles", y = "Sample Quantiles") +
  theme_minimal() +
  theme(legend.position = "top", 
        axis.text = element_text(size = 14), axis.title = element_text(size = 16),
        legend.text = element_text(size = 12), legend.title = element_text(size = 14),
        strip.text = element_text(size = 13))

# Create plot of p-values for Shapiro.Wilk test
sw_df = all_data2 %>%
  group_by(dataset, mode) %>%
  summarise(p_value = shapiro.test(energy_nvidia_scaled)$p.value)  # ad.test or ks.test??

ggplot(sw_df, aes(x = dataset, y = p_value, color = mode)) +
  geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
  scale_color_manual(values = c("blue", "green", "red"), name = "Training mode",
                     labels = c("Base training", "Layer freezing", "Model quantization")) +
  labs(x = "Dataset", y = "Shapiro-Wilk p-value") +
  geom_hline(yintercept = 0.05, color="red") +
  theme_minimal() +
  theme(legend.position = "top", 
        axis.text = element_text(size = 14), axis.title = element_text(size = 16),
        legend.text = element_text(size = 12), legend.title = element_text(size = 14),
        axis.text.x = element_text(angle = 20, vjust = 1, hjust = 1))

# Create plot of p-values
sw_df <- all_data %>%  # Choose data!
  group_by(dataset, mode) %>%
  summarise(p_value = shapiro.test(energy_nvidia)$p.value)

ggplot(sw_df, aes(x = dataset, y = p_value, color = mode)) +
  geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
  scale_color_manual(values = c("red", "green", "blue")) +
  labs(x = "Dataset", y = "Shapiro-Wilk p-value") +
  theme(axis.text.x = element_text(angle = 20, vjust = 1, hjust = 1)) +
  geom_hline(yintercept = 0.05, color="red") +
  theme_minimal() +
  theme(legend.position = "top", 
        axis.text = element_text(size = 14), axis.title = element_text(size = 16),
        legend.text = element_text(size = 12), legend.title = element_text(size = 14),
        axis.text.x = element_text(angle = 20, vjust = 1, hjust = 1))
```

```{r}
sw_df <- all_data2 %>%
  group_by(dataset, mode) %>%
  summarise(p_value = shapiro.test(energy_nvidia)$p.value)

# Create bar plot of p-values
ggplot(sw_df, aes(x = dataset, y = p_value, color = mode)) +
  geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
  scale_color_manual(values = c("red", "green", "blue")) +
  labs(x = "Dataset", y = "Shapiro-Wilk p-value") +
  theme(axis.text.x = element_text(angle = 20, vjust = 1, hjust = 1)) +
  geom_hline(yintercept = 0.05, color="red")
```

### Coefs estimation for energy against mode

```{r}
mode_means = all_data %>% 
  group_by(dataset, mode) %>% 
  summarise(mean_energy = mean(energy_nvidia)) %>%  # Energy measure?
  pivot_wider(names_from = mode, values_from = mean_energy) %>%
  as.data.frame()

ggplot(mode_means, aes(x = base, y = quant, color = "quant")) +
  geom_point() +
  geom_point(aes(y = freeze, color = "freeze")) +
  geom_abline(intercept = 0, slope = 1, color = "blue", linetype = "dashed") +
  scale_color_manual(values = c("green", "red"), name = "Training mode",
                     labels = c("Layer freezing", "Model quantization")) +
  labs(x = "Mean energy for base mode (kW h)", y = "Mean energy (kW h)") +
  geom_smooth(method = "lm", aes(x = base, y = quant, color = "quant"), 
              se = FALSE, formula = y ~ x, data = mode_means, linetype = "dashed", size=0.5) +
  geom_smooth(method = "lm", aes(x = base, y = freeze, color = "freeze"), 
              se = FALSE, formula = y ~ x, data = mode_means, linetype = "dashed", size=0.5) +
  theme_minimal() +
  theme(
    legend.position = "top", 
    axis.text = element_text(size = 14), axis.title = element_text(size = 16),
    legend.text = element_text(size = 12), legend.title = element_text(size = 14)
  )

ggplot(mode_means, aes(x = base, y = quant, color = "quant")) +
  geom_point() +
  geom_point(aes(y = freeze, color = "freeze")) +
  geom_abline(intercept = 0, slope = 1, color = "blue", linetype = "dashed") +
  scale_color_manual(values = c("green", "red"), name = "Training mode",
                     labels = c("Layer freezing", "Model quantization")) +
  labs(x = "Mean energy for base mode (kW h)", y = "Mean energy (kW h)") +
  geom_smooth(method = "lm", aes(x = base, y = quant, color = "quant"), 
              se = FALSE, formula = y ~ x, data = mode_means, linetype = "dashed", size=0.5) +
  geom_smooth(method = "lm", aes(x = base, y = freeze, color = "freeze"), 
              se = FALSE, formula = y ~ x, data = mode_means, linetype = "dashed", size=0.5) +
  coord_cartesian(xlim = c(0, 0.0003), ylim = c(0, 0.0003)) +
  theme_minimal() +  # .0003 nv, .001 carbon, .00015 emissions
  theme(
    legend.position = "top", 
    axis.text = element_text(size = 14), axis.title = element_text(size = 16),
    legend.text = element_text(size = 12), legend.title = element_text(size = 14)
  )

quant.lm = lm(quant~base, data=mode_means)
print(summary(quant.lm))
t.quant = (coef(summary(quant.lm))[2,1] - 1) / sqrt(vcov(quant.lm)[2,2])
print(2 * pt(-abs(t.quant), df = df.residual(quant.lm)))

freeze.lm = lm(freeze~base, data=mode_means)
print(summary(freeze.lm))
t.freeze = (coef(summary(freeze.lm))[2,1] - 1) / sqrt(vcov(freeze.lm)[2,2])
print(2 * pt(-abs(t.freeze), df = df.residual(freeze.lm)))

quant.lm = lm(quant~0+base, data=mode_means)
print(summary(quant.lm))
t.quant = (coef(summary(quant.lm))[1,1] - 1) / sqrt(vcov(quant.lm)[1,1])
print(2 * pt(-abs(t.quant), df = df.residual(quant.lm)))

freeze.lm = lm(freeze~0+base, data=mode_means)
print(summary(freeze.lm))
t.freeze = (coef(summary(freeze.lm))[1,1] - 1) / sqrt(vcov(freeze.lm)[1,1])
print(2 * pt(-abs(t.freeze), df = df.residual(freeze.lm)))

ggplot(mode_means, aes(x = base, y = quant, color = "quant")) +
  geom_point() +
  geom_point(aes(y = freeze, color = "freeze")) +
  geom_abline(intercept = 0, slope = 1, color = "blue", linetype = "dashed") +
  scale_color_manual(values = c("green", "red"), name = "Training mode",
                     labels = c("Layer freezing", "Model quantization")) +
  labs(x = "Mean energy for base mode (kW h)", y = "Mean energy (kW h)") +
  geom_smooth(method = "lm", aes(x = base, y = quant, color = "quant"), 
              se = FALSE, formula = y ~ 0 + x, data = mode_means, linetype = "dashed", size=0.5) +
  geom_smooth(method = "lm", aes(x = base, y = freeze, color = "freeze"), 
              se = FALSE, formula = y ~ 0 + x, data = mode_means, linetype = "dashed", size=0.5) +
  theme_minimal() +
  theme(
    legend.position = "top", 
    axis.text = element_text(size = 14), axis.title = element_text(size = 16),
    legend.text = element_text(size = 12), legend.title = element_text(size = 14)
  )

ggplot(mode_means, aes(x = base, y = quant, color = "quant")) +
  geom_point() +
  geom_point(aes(y = freeze, color = "freeze")) +
  geom_abline(intercept = 0, slope = 1, color = "blue", linetype = "dashed") +
  scale_color_manual(values = c("green", "red"), name = "Training mode",
                     labels = c("Layer freezing", "Model quantization")) +
  labs(x = "Mean energy for base mode (kW h)", y = "Mean energy (kW h)") +
  geom_smooth(method = "lm", aes(x = base, y = quant, color = "quant"), 
              se = FALSE, formula = y ~ 0 + x, data = mode_means, linetype = "dashed", size=0.5) +
  geom_smooth(method = "lm", aes(x = base, y = freeze, color = "freeze"), 
              se = FALSE, formula = y ~ 0 + x, data = mode_means, linetype = "dashed", size=0.5) +
  coord_cartesian(xlim = c(0, 0.0003), ylim = c(0, 0.0003))   +
  theme_minimal() +# .0003 nv, .001 carbon, .00015 emissions
  theme(
    legend.position = "top", 
    axis.text = element_text(size = 14), axis.title = element_text(size = 16),
    legend.text = element_text(size = 12), legend.title = element_text(size = 14)
  )

ggplot(mode_means, aes(x = base, y = quant, color = "quant")) +
  geom_point() +
  geom_point(aes(y = freeze, color = "freeze")) +
  geom_abline(intercept = 0, slope = 1, color = "blue", linetype = "dashed") +
  scale_color_manual(values = c("green", "red"), name = "Training mode",
                     labels = c("Layer freezing", "Model quantization")) +
  labs(x = "Mean energy for base mode (kW h)", y = "Mean energy (kW h)") +
  geom_smooth(method = "lm", aes(x = base, y = quant, color = "quant"), 
              se = FALSE, formula = y ~ 0 + x, data = mode_means, linetype = "dashed", size=0.5) +
  geom_smooth(method = "lm", aes(x = base, y = freeze, color = "freeze"), 
              se = FALSE, formula = y ~ 0 + x, data = mode_means, linetype = "dashed", size=0.5) +
  theme_minimal() +
  scale_x_log10() +
  scale_y_log10()
```

```{r}
n.rep = 1
options(dplyr.summarise.inform = FALSE)
time.measure = system.time({
  for (rep in 1:n.rep) {
    errors.4 = c()
    gt = c()
    for (dataset in datasets$dataset) {
      part_data = all_data[all_data$dataset != dataset,]
      extra_data = all_data[all_data$dataset == dataset,]
      mode_means = part_data %>% 
        group_by(dataset, mode) %>% 
        summarise(mean_energy = mean(energy_nvidia)) %>%  # Energy measure?
        pivot_wider(names_from = mode, values_from = mean_energy) %>%
        as.data.frame()
      quant.change = lm(quant~0+base, data=mode_means)$coefficients[[1]]
      freeze.change = lm(freeze~0+base, data=mode_means)$coefficients[[1]]
      changes = c(quant.change, freeze.change)
      names(changes) = c("quant", "freeze")
      
      n.count = 0
      for (i in 1:nrow(extra_data)) {
        if (extra_data[i,"epoch"] <= 5) {next}
        n.count = n.count + 1
        previous_data = get_all_previous(i, extra_data)
        if (extra_data[i,"mode"] == "base") {
          pred = mean(previous_data$energy_nvidia)
        }
        else if (extra_data[i,"mode"] != previous_data[nrow(previous_data),"mode"]) {
          pred = mean(previous_data$energy_nvidia) * changes[extra_data[i,"mode"]]
        }
        else {
          pred = mean(previous_data$energy_nvidia[previous_data$mode == extra_data[i,"mode"]])
        }
        #preds = c(preds, pred)
        errors.4 = c(errors.4, pred - extra_data[i,"energy_nvidia"])
        #data_pred = rbind(data_pred, extra_data[i,c("dataset", "mode", "epoch", "intervention")])
        gt = c(gt, extra_data[i,"energy_nvidia"])
      }
    }
  }
})
#data_pred = data_pred[2:nrow(data_pred),]
#data_pred["error"] = errors.4

print(time.measure[3]/n.rep)
print(sum(errors.4**2))
print(mean(errors.4**2))
print(mean(abs(errors.4)))
print(mean(abs(errors.4)/gt))
```

```{r}
err = matrix((errors.4)/gt, ncol=12)
err2 = rowMeans(err)
plot(err2)
abline(h=0)
abline(v=95)
abline(v=185)
abline(v=255)
```

## Score prediction

```{r}
panel.data2 = all_data[str_split("dataset,epoch,intervention,mode,val_accuracy,accuracy,score,energy_nvidia,energy_nvidia_cumulative", ",")[[1]]]
for (attr in c("val_accuracy", "accuracy", "mode")) {
  for (n in 1:10) {
    panel.data2[[paste0(attr, "_lag", n)]] <- apply(panel.data2, 1, get_prev, df=panel.data2, attribute=attr, n=n)
  }
}

get_all_previous = function(i, df) {
  if (df[i,"intervention"] == 0) {
    return (df[df$intervention == 0 & df$mode == df[i,"mode"] & df$epoch < df[i,"epoch"],])
  }
  return(rbind(
    df[df$intervention == 0 & df$epoch < df[i,"intervention"],],
    df[df$intervention == df[i,"intervention"] & df$mode == df[i,"mode"] & df$epoch < df[i,"epoch"],]
  ))
}
```

```{r}
n.rep = 1
options(dplyr.summarise.inform = FALSE)
time.measure = system.time({
  for (rep in 1:n.rep) {
    errors.sc = c()
    gt = c()
    preds = c()
    gt.acc = c()
    preds.acc = c()
    gt.energy = c()
    preds.energy = c()
    epochs.count = c()
    data_pred = data.frame(dataset="0", mode="0", epoch=0, intervention=0)
    for (dataset in datasets$dataset) {
      
      part_data = panel.data2[panel.data2$dataset != dataset, c(1:13, 20:23, 30)]
      part_data[part_data == "quant"] = "base"
      extra_data = panel.data2[panel.data2$dataset == dataset, c(1:13, 20:23, 30)]
      res.fe = lm(val_accuracy ~ dataset + val_accuracy_lag1 + val_accuracy_lag2 + 
                  val_accuracy_lag3 + val_accuracy_lag4 + mode_lag1 + mode, data=part_data)
      coefs = res.fe$coefficients[12:17]
      
      mode_means = part_data %>% 
        group_by(dataset, mode) %>% 
        summarise(mean_energy = mean(energy_nvidia)) %>%  # Energy measure?
        pivot_wider(names_from = mode, values_from = mean_energy) %>%
        as.data.frame()
      #quant.change = lm(quant~0+base, data=mode_means)$coefficients[[1]]
      freeze.change = lm(freeze~0+base, data=mode_means)$coefficients[[1]]
      #changes = c(quant.change, freeze.change)
      #names(changes) = c("quant", "freeze")
      
      n.count = 0
      for (i in 1:nrow(extra_data)) {
        if (extra_data[i,"epoch"] <= 6) {next}
        n.count = n.count + 1
        previous_data = get_all_previous(i, extra_data)
        if (extra_data[i,"mode"] == "base") {
          pred.energy = mean(previous_data$energy_nvidia)
        }
        else if (extra_data[i,"mode"] != previous_data[nrow(previous_data),"mode"]) {
          pred.energy = mean(previous_data$energy_nvidia) * freeze.change
        }
        else {
          pred.energy = mean(previous_data$energy_nvidia[previous_data$mode == extra_data[i,"mode"]])
        }
        
        previous_data = get_all_previous(i, extra_data)[c(10:13,18,4,5,8,9)] %>% drop_na()
        previous_data[5:6] = (previous_data[5:6] == "freeze")
        previous_preds = colSums(t(previous_data[1:6]) * coefs)
        #new_fit = lm(previous_data$val_accuracy ~ previous_preds)
        offset = mean(previous_data$val_accuracy) - mean(previous_preds)
        pred.acc = c(as.numeric(extra_data[i,10:13]), extra_data[i,18]=="freeze", extra_data[i,4]=="freeze")
        #pred.acc = sum(pred.acc * coefs) * new_fit$coefficients[2] + new_fit$coefficients[1]
        pred.acc = sum(pred.acc * coefs) + offset
        
        pred = pred.acc / (previous_data[nrow(previous_data),"energy_nvidia_cumulative"] + pred.energy)
        preds = c(preds, pred)
        preds.acc = c(preds.acc, pred.acc)
        preds.energy = c(preds.energy, pred.energy)
        epochs.count = c(epochs.count, extra_data[i,"epoch"])
        gt = c(gt, extra_data[i,"score"])
        gt.acc = c(gt.acc, extra_data[i,"val_accuracy"])
        gt.energy = c(gt.energy, extra_data[i,"energy_nvidia"])
      }
    }
  }
})

errors.sc = preds - gt
errors.acc = preds.acc - gt.acc
errors.energy = preds.energy - gt.energy

print(time.measure[3]/n.rep)
print(sum(errors.sc**2))
print(mean(errors.sc**2))
print(mean(abs(errors.sc)))
print(mean(abs(errors.sc)/gt))
```

## Energy savings

```{r}
predict_branch = function(values, coefs, offset, mode, energy_measure, energy_pred) {
  preds = c()
  for (j in 1:10) {
    pred = sum(values * coefs) + offset
    values = c(pred, values[1:3], mode, mode)
    pred = pred / (energy_measure + j*energy_pred)
    preds = c(preds, pred)
  }
  return (preds)
}

get_best_epoch = function(row, mode, energy_pred, coefs, offset, previous_score) {
  mode = (mode == "freeze")
  values = c(as.numeric(row[1:4]), row[5] == "freeze", mode)
  energy_measure = row[[10]] - row[[9]]
  score_pred = predict_branch(values, coefs, offset, mode, energy_measure, energy_pred)
  
  score_tot = c(previous_score, score_pred)
  res = nls(score_tot ~ a / (b + 1:length(score_tot)), start = c(a=100, b=100), control = nls.control(minFactor = 1e-10, maxiter = 10000))
  if (coef(res)["a"] < 0) {
    res = nls(score_tot ~ a / (b + 1:length(score_tot)), start = c(a=1000, b=1000), control = nls.control(minFactor = 1e-10, maxiter = 10000))
  }
  epoch.opt = round(sqrt(coef(res)["a"]) - coef(res)["b"])
  score.opt = coef(res)["a"] / (coef(res)["b"] + epoch.opt)
  return (c("epoch" = epoch.opt, "score" = score.opt))
}

get_all_previous_value = function(epoch, mode, intervention, df) {
  if (intervention == 0) {
    return (df[df$intervention == 0 & df$mode == mode & df$epoch <= epoch,])
  }
  return(rbind(
    df[df$intervention == 0 & df$epoch <= intervention,],
    df[df$intervention == intervention & df$mode == mode & df$epoch <= epoch,]
  ))
}


simulate = function(dataset) {
  # Define data
  part_data = panel.data2[panel.data$dataset != dataset, c(1:13, 20:23, 30)] %>% drop_na()
  part_data[part_data == "quant"] = "base"
  extra_data = panel.data2[panel.data$dataset == dataset & 
    !(panel.data$intervention == 0 & panel.data$mode != "base"), c(1:13, 20:23, 30)]# %>% drop_na()
  
  # Pre compute for acc
  res.fe = lm(val_accuracy ~ dataset + val_accuracy_lag1 + val_accuracy_lag2 + 
                  val_accuracy_lag3 + val_accuracy_lag4 + mode_lag1 + mode, data=part_data)
  coefs = res.fe$coefficients[12:17]
  # Pre compute for energy
  mode_means = part_data %>% 
    group_by(dataset, mode) %>% 
    summarise(mean_energy = mean(energy_nvidia)) %>%
    pivot_wider(names_from = mode, values_from = mean_energy) %>%
    as.data.frame()
  change = lm(freeze~0+base, data=mode_means)$coefficients[[1]]
  
  current_mode = "base"
  intervention = 0
  for (i in 6:50) {
    # Predict onward
    previous_data = get_all_previous_value(i, current_mode, intervention, extra_data)[c(10:13,18,4,5,7:9,1:3)]
    row = previous_data[i,]
    previous_data = previous_data[1:(i-1),]
    previous_score = previous_data$score
    previous_data = drop_na(previous_data)
    previous_data[5:6] = (previous_data[5:6] == "freeze")
    
    previous_preds = colSums(t(previous_data[1:6]) * coefs)
    offset = mean(previous_data$val_accuracy) - mean(previous_preds)
    energy_pred = mean(previous_data$energy_nvidia) * ifelse(current_mode == "base", 1, change)
    optim = get_best_epoch(row, current_mode, energy_pred, coefs, offset, previous_score)
    if (optim["epoch.a"] <= i) {
      return (row)
    }
    if (current_mode == "base" & i %% 10 == 0) {
      # Previously computed epoch.opt was for base, let's consider freezing
      optim.freeze = get_best_epoch(row, "freeze", energy_pred * change, coefs, offset, previous_score)
      if (optim.freeze["score.a"] > optim["score.a"]) {
        if (optim["epoch.a"] <= i) {
          return (row)
        }
        current_mode = "freeze"
        intervention = i
      }
    }
  }
  return (row)
}
```

```{r}
results = data.frame()
for (dataset in datasets$dataset) {
  optim = simulate(dataset)
  results = rbind(results, optim)
}
baseline = data.frame()
for (dataset in datasets$dataset) {
  final = all_data[all_data$dataset == dataset & all_data$mode == "base" & all_data$epoch == 50,]
  baseline = rbind(baseline, final)
}

print(c(mean(results$energy_nvidia_cumulative), mean(baseline$energy_nvidia_cumulative)))
print(mean(results$energy_nvidia_cumulative / baseline$energy_nvidia_cumulative))
print(c(mean(results$val_accuracy), mean(baseline$val_accuracy)))
print(mean(results$val_accuracy / baseline$val_accuracy))
```

## Visualization

```{r}
predict_acc = function(dataset, intervention, mode) {
  preds = c()
  part_data = panel.data[panel.data$dataset != dataset, c(1:6, 7:10, 17:20, 27)] %>% drop_na()
  part_data[part_data == "quant"] = "base"
  extra_data = panel.data[panel.data$dataset == dataset & 
   ((all_data$intervention == intervention & all_data$mode == mode) |
    (all_data$epoch <= intervention & all_data$mode == "base")), c(1:6, 7:10, 17:20, 27)] %>% drop_na()
  res.fe = lm(val_accuracy ~ dataset + val_accuracy_lag1 + val_accuracy_lag2 + 
                  val_accuracy_lag3 + val_accuracy_lag4 + mode_lag1 + mode, data=part_data)
  coefs = res.fe$coefficients[12:17]
  n.count = 0
  for (i in 1:nrow(extra_data)) {
    if (extra_data[i,"epoch"] <= 6) {next}
    n.count = n.count + 1
    previous_data = get_all_previous(i, extra_data)[c(7:10,15,4,5)]
    previous_data[5:6] = (previous_data[5:6] == "freeze")
    previous_preds = colSums(t(previous_data[1:6]) * coefs)
    offset = mean(previous_data$val_accuracy) - mean(previous_preds)
    
    pred = c(as.numeric(extra_data[i,7:10]), extra_data[i,15]=="freeze", extra_data[i,4]=="freeze")
    pred = sum(pred * coefs) + offset
    preds = c(preds, pred)
  }
  return(preds)
}

predict_energy = function(dataset, intervention, mode) {
  part_data = all_data[all_data$dataset != dataset,]
  extra_data = all_data[panel.data$dataset == dataset & 
   ((all_data$intervention == intervention & all_data$mode == mode) |
    (all_data$epoch <= intervention & all_data$mode == "base")),]
  mode_means = part_data %>% 
    group_by(dataset, mode) %>% 
    summarise(mean_energy = mean(energy_nvidia)) %>%  # Energy measure?
    pivot_wider(names_from = mode, values_from = mean_energy) %>%
    as.data.frame()
  quant.change = lm(quant~0+base, data=mode_means)$coefficients[[1]]
  freeze.change = lm(freeze~0+base, data=mode_means)$coefficients[[1]]
  changes = c(quant.change, freeze.change)
  names(changes) = c("quant", "freeze")

  preds = c()
  for (i in 1:nrow(extra_data)) {
    if (extra_data[i,"epoch"] <= 5) {next}
    previous_data = get_all_previous(i, extra_data)
    if (extra_data[i,"mode"] == "base") {
      pred = mean(previous_data$energy_nvidia)
    }
    else if (extra_data[i,"mode"] != previous_data[nrow(previous_data),"mode"]) {
      pred = mean(previous_data$energy_nvidia) * changes[extra_data[i,"mode"]]
    }
    else {
      pred = mean(previous_data$energy_nvidia[previous_data$mode == extra_data[i,"mode"]])
    }
    preds = c(preds, pred)
  }
  return (preds)
}

predict_score = function(dataset, intervention, mode) {
  acc_pred = predict_acc(dataset, intervention, mode)
  energy_pred = predict_energy(dataset, intervention, mode)
  energy_pred = energy_pred[(length(energy_pred)-length(acc_pred)+1):length(energy_pred)]
  energy_cum = all_data[
    all_data$dataset==dataset & 
    ((all_data$intervention == intervention & all_data$mode == mode) |
     (all_data$epoch <= intervention & all_data$mode == "base")), "energy_nvidia_cumulative"
  ]
  energy_cum_pred = energy_cum[(N-length(energy_pred)):(N-1)] + energy_pred
  score_pred = acc_pred / energy_cum_pred
  return (score_pred)
}
```

```{r}
# to choose;
var.pred = "score" # one of: val_accuracy, energy_nvidia, score
mode = "quant"

func.pred = ifelse(
  var.pred == "val_accuracy", predict_acc, 
  ifelse(var.pred == "energy_nvidia", predict_energy, predict_score)
)
label = ifelse(
  var.pred == "val_accuracy", "Validation accuracy", 
  ifelse(var.pred == "energy_nvidia", "Energy consumed (kW h)", "Trade-off score")
)
color = ifelse(mode == "freeze", "green", "red")

par(mfrow=c(2, 2), mar=c(3,3,1,0), oma=c(0,0,0,0), mgp=c(1.6,0.5,0),
    cex.main=1.2, cex.lab=1.1, cex.axis=1)

i = 0
for (dataset in datasets_sample) {
  intervention = ifelse(i < 2, 20, 30)
  
  gt = all_data[
    all_data$dataset==dataset & 
    ((all_data$intervention == intervention & all_data$mode == mode) |
     (all_data$epoch <= intervention & all_data$mode == "base")), var.pred
  ]
  pred = func.pred(dataset, intervention, mode)
  
  plot(gt, col = c(rep("blue", intervention), rep(color, N - intervention)), xlab="Epoch", ylab=label, main=dataset)
  lines(7:intervention, pred[1:(intervention-6)], col="blue")
  lines(intervention:N, pred[(intervention-6):(N-6)], col=color)
  i = i + 1
}
```


